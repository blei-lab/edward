{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#  Probabilistic Matrix Factorization of the MovieLens Ratings\n",
    "\n",
    "Something something . Matrix factorization is a simple and powerful technique for predicting user's ratings of items using embedding in a latent space.\n",
    "\n",
    "Modern methods have many useful adaptations, but the general system predicts user $u$'s rating of item $i$, $r_{u,i}$  as \n",
    "  *  $r_{u,i} = \\mu + \\beta_u + \\beta_i + \\vec{v}_u^T \\cdot \\vec{v}_i^T$\n",
    "  *  $\\mu$, $\\beta_u$, and $\\beta_i$ are overall mean ratings and offsets for users and movies\n",
    "  *  $\\vec{v}_i, \\vec{v}_u \\in \\mathbb{R}^K$ are the user's and movie's embeddings in a $K$ dimensional space.\n",
    "  *  We regularize user and item vectors by modeling them as coming from a multivariate gaussian, which can be learned or predetermined $\\vec{v}_u \\sim N(0, \\Lambda_{\\text{Users}})$ and $\\vec{v}_i \\sim N(0, \\Lambda_{\\text{Movies}})$.\n",
    "\n",
    "The most famous application of PMF for recomendation systems is probably Netflix's.  Their system is described in [this paper](https://papers.nips.cc/paper/3208-probabilistic-matrix-factorization.pdf) and you can also find a readable overview [here](https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf).  Netflix took down the original dataset due to privacy concerns, but you can still run the same model using the [MovieLens data](https://grouplens.org/datasets/movielens/20m/).\n",
    "\n",
    "Need to cite `MovieLens` with ```F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4, Article 19 (December 2015), 19 pages. DOI=http://dx.doi.org/10.1145/2827872```.\n",
    "\n",
    "The MovieLens data comes contains 20,000,263 ratings of 27,278 movies by 138,493 users. It also contains free text tags, but we will not use them here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "##  Read in the Data\n",
    "\n",
    "Download [the data](https://grouplens.org/datasets/movielens/) and unzip.\n",
    "\n",
    "We will only use `ml-20/movies.csv` and `ml-20/ratings.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/pandas/core/computation/__init__.py:18: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import edward as ed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "movies = pd.read_csv('~/ml-20m/movies.csv')\n",
    "ratings = pd.read_csv('~/ml-20m/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   movieId                               title  \\\n0        1                    Toy Story (1995)   \n1        2                      Jumanji (1995)   \n2        3             Grumpier Old Men (1995)   \n3        4            Waiting to Exhale (1995)   \n4        5  Father of the Bride Part II (1995)   \n\n                                        genres  \n0  Adventure|Animation|Children|Comedy|Fantasy  \n1                   Adventure|Children|Fantasy  \n2                               Comedy|Romance  \n3                         Comedy|Drama|Romance  \n4                                       Comedy  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27278, 3)\n"
     ]
    }
   ],
   "source": [
    "print(movies.shape)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   userId  movieId  rating   timestamp\n0       1        2     3.5  1112486027\n1       1       29     3.5  1112484676\n2       1       32     3.5  1112484819\n3       1       47     3.5  1112484727\n4       1       50     3.5  1112484580"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000263, 4)\n"
     ]
    }
   ],
   "source": [
    "print(ratings.shape)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's cherry pick a few movies whose parameters we will track.  We'll pick the ones with the most ratings - hopefully our latent dimensions will be interpretable. \n",
    "\n",
    "We'll also bring in the titles now.  We'll need to remap the user and movie IDs, and bringing in the titles helps make sure we don't make mistakes mapping them back later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ratings = ratings.merge(movies, on = 'movieId', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   userId  movieId  rating   timestamp  \\\n0       1        2     3.5  1112486027   \n1       1       29     3.5  1112484676   \n2       1       32     3.5  1112484819   \n3       1       47     3.5  1112484727   \n4       1       50     3.5  1112484580   \n\n                                               title  \\\n0                                     Jumanji (1995)   \n1  City of Lost Children, The (Cité des enfants p...   \n2          Twelve Monkeys (a.k.a. 12 Monkeys) (1995)   \n3                        Seven (a.k.a. Se7en) (1995)   \n4                         Usual Suspects, The (1995)   \n\n                                   genres  \n0              Adventure|Children|Fantasy  \n1  Adventure|Drama|Fantasy|Mystery|Sci-Fi  \n2                 Mystery|Sci-Fi|Thriller  \n3                        Mystery|Thriller  \n4                  Crime|Mystery|Thriller  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pulp Fiction (1994)                 67310\nForrest Gump (1994)                 66172\nShawshank Redemption, The (1994)    63366\nSilence of the Lambs, The (1991)    63299\nJurassic Park (1993)                59715\nName: title, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['title'].value_counts()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Shawshank Redemption, The (1994)             55807\nPulp Fiction (1994)                          52353\nSilence of the Lambs, The (1991)             50114\nForrest Gump (1994)                          47331\nStar Wars: Episode IV - A New Hope (1977)    42612\nName: title, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.loc[ratings['rating'] >= 4.0]['title'].value_counts()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dumb & Dumber (Dumb and Dumber) (1994)    4578\nAce Ventura: Pet Detective (1994)         4323\nAce Ventura: When Nature Calls (1995)     3976\nWaterworld (1995)                         3013\nBlair Witch Project, The (1999)           2992\nName: title, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.loc[ratings['rating'] <= 1.0]['title'].value_counts()[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "##  Model Definition\n",
    "\n",
    "Let's go ahead and define our model before we reformat our data.\n",
    "\n",
    "We will use a vanilla PMF - exactly the one defined above, with predetermined $\\Lambda_{\\text{movies}} = \\Lambda_{\\text{users}} = I_K$ and $K=3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from edward.models import Normal\n",
    "#  This will need to change if you train/test split\n",
    "N_users = len(set(ratings.userId))\n",
    "N_movies = len(set(ratings.movieId))\n",
    "N_ratings = ratings.shape[0]\n",
    "K = 2\n",
    "\n",
    "lnvar_users = Normal(loc=tf.zeros([1]), scale=tf.ones([1]))\n",
    "lnvar_movies = Normal(loc=tf.zeros([1]), scale=tf.ones([1]))\n",
    "sigma_users = tf.sqrt(tf.exp(lnvar_users))\n",
    "sigma_movies = tf.sqrt(tf.exp(lnvar_users))\n",
    "\n",
    "user_vecs = Normal(loc = tf.zeros([N_users, K]), \n",
    "                   scale = sigma_users * tf.ones([N_users, K]))\n",
    "movie_vecs = Normal(loc = tf.zeros([N_movies, K]), \n",
    "                    scale = sigma_movies * tf.ones([N_movies, K]))\n",
    "\n",
    "#  Somewhat hacky prior on mu\n",
    "mu = Normal(loc = 2.5*tf.ones([1]), \n",
    "            scale = tf.ones([1]))\n",
    "\n",
    "user_betas = Normal(loc = tf.zeros([N_users]), \n",
    "                    scale = sigma_users * tf.ones([N_users]))\n",
    "movie_betas = Normal(loc = tf.zeros([N_movies]), \n",
    "                     scale = sigma_movies * tf.ones([N_movies]))\n",
    "\n",
    "#  Placeholders for data inputs\n",
    "user_ids = tf.placeholder(tf.int32, [N_ratings])\n",
    "movie_ids = tf.placeholder(tf.int32, [N_ratings])\n",
    "\n",
    "predicted_ratings = tf.reduce_sum(tf.multiply(\n",
    "    tf.gather(user_vecs, user_ids),\n",
    "    tf.gather(movie_vecs, movie_ids)\n",
    ")) + \\\n",
    "    tf.gather(user_betas, user_ids) + \\\n",
    "    tf.gather(movie_betas, movie_ids) + \\\n",
    "    mu\n",
    "\n",
    "obs_ratings = Normal(loc=predicted_ratings, scale = tf.ones([N_ratings]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "##  Inference Definition\n",
    "\n",
    "We have now sret up a probablistic graph for generating ratings from our learnable paramters (mu, offsets, and vectors).  We now explicitly define our inference.  Edward makes it easy to swap out sampling, ML, and variational methods.  We'll use simple MFVI.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "user_ids_train = ratings['userId']\n",
    "movie_ids_train = ratings['movieId'].astype('category').cat.codes\n",
    "\n",
    "user_ids_train = user_ids_train.values.astype(int) - 1\n",
    "movie_ids_train = movie_ids_train.values.astype(int)\n",
    "ratings_train = ratings['rating'].values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# INFERENCE\n",
    "q_user_vecs = Normal(loc=tf.Variable(tf.random_normal([N_users, K])),\n",
    "                     scale=tf.nn.softplus(tf.Variable(tf.random_normal([N_users, K]))))\n",
    "q_movie_vecs = Normal(loc=tf.Variable(tf.random_normal([N_movies, K])),\n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([N_movies, K]))))\n",
    "q_user_betas = Normal(loc=tf.Variable(tf.random_normal([N_users])),\n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([N_users]))))\n",
    "q_movie_betas = Normal(loc=tf.Variable(tf.random_normal([N_movies])),\n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([N_movies]))))\n",
    "\n",
    "q_mu = Normal(loc=tf.Variable(tf.random_normal([1])),\n",
    "              scale=tf.nn.softplus(tf.Variable(tf.random_normal([1]))))\n",
    "q_lnvar_users = Normal(loc=tf.Variable(tf.random_normal([1])),\n",
    "                       scale=tf.nn.softplus(tf.Variable(tf.random_normal([1]))))\n",
    "q_lnvar_movies = Normal(loc=tf.Variable(tf.random_normal([1])),\n",
    "                        scale=tf.nn.softplus(tf.Variable(tf.random_normal([1]))))\n",
    "\n",
    "                                    \n",
    "parameter_inferences = {\n",
    "    user_vecs: q_user_vecs,\n",
    "    movie_vecs: q_movie_vecs,\n",
    "    user_betas: q_user_betas,\n",
    "    movie_betas: q_movie_betas,\n",
    "    mu: q_mu,\n",
    "    lnvar_users: q_lnvar_users,\n",
    "    lnvar_movies: q_lnvar_movies\n",
    "}\n",
    "train_data = {\n",
    "    user_ids: user_ids_train,\n",
    "    movie_ids: movie_ids_train,\n",
    "    obs_ratings: ratings_train\n",
    "}\n",
    "\n",
    "inference = ed.KLqp(parameter_inferences,\n",
    "                    train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#  Run the Inference\n",
    "\n",
    "We now have everything set up and can let SGD run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-9)\n",
    "\n",
    "inference.initialize(optimizer = optimizer,\n",
    "                     n_print=10, n_iter=500)\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500    Loss per rating: 104967204.321 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 490    Loss per rating: 67204482.8075 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 480    Loss per rating: 109307426.448 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 470    Loss per rating: 30528340.1774 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 460    Loss per rating: 502415070.493 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 450    Loss per rating: 12991414.8509 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 440    Loss per rating: 56615836.5202 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 430    Loss per rating: 20602596.5978 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 420    Loss per rating: 80806109.6955 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 410    Loss per rating: 39704011.1366 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 400    Loss per rating: 60994947.7225 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 390    Loss per rating: 119919090.773 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 380    Loss per rating: 70704412.3438 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 370    Loss per rating: 72816266.9686 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 360    Loss per rating: 3677134.87235 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 350    Loss per rating: 24391006.5697 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 340    Loss per rating: 116629296.459 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 330    Loss per rating: 167832565.572 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 320    Loss per rating: 73966605.1448 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 310    Loss per rating: 10493912.4663 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 300    Loss per rating: 6554782.58157 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 290    Loss per rating: 29326489.9145 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 280    Loss per rating: 154010254.087 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 270    Loss per rating: 67518534.7394 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 260    Loss per rating: 503227882.365 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 250    Loss per rating: 100438348.368 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 240    Loss per rating: 185146330.855 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 230    Loss per rating: 18134529.4517 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 220    Loss per rating: 47617703.0815 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 210    Loss per rating: 91218792.1445 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200    Loss per rating: 148432856.055 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 190    Loss per rating: 435390249.173 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 180    Loss per rating: 88064663.3262 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 170    Loss per rating: 3031102.90144 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 160    Loss per rating: 7079895.40682 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 150    Loss per rating: 101282519.8 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 140    Loss per rating: 210167743.093 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 130    Loss per rating: 170484109.295 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 120    Loss per rating: 51480284.15 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 110    Loss per rating: 201161060.097 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100    Loss per rating: 227039830.485 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 90    Loss per rating: 11566097.5261 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 80    Loss per rating: 8589374.52892 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 70    Loss per rating: 96384549.8171 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 60    Loss per rating: 25166180.9306 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 50    Loss per rating: 37562837.0347 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 40    Loss per rating: 6513808.12575 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 30    Loss per rating: 39516595.3211 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 20    Loss per rating: 676.476685132 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 10    Loss per rating: 193482605.115 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(inference.n_iter):\n",
    "    info_dict = inference.update()\n",
    "    #inference.print_progress(info_dict)\n",
    "    if info_dict['t'] % inference.n_print == 0:\n",
    "        l_per_rating = info_dict['loss'] / (1.0 * N_ratings)\n",
    "        print('Iter: {}    Loss per rating: {} \\n'.format(info_dict['t'], l_per_rating))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#  Model Criticism\n",
    "Just as a first sanity check, let's see which movies the model thinks are best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       movieId  movie_cat_code  fit_beta  \\\n9609     30958            9609 -3.971159   \n23971   114492           23971 -3.960724   \n24005   114652           24005 -3.836536   \n25525   124050           25525 -3.810666   \n8605     26096            8605 -3.712745   \n\n                                                   title              genres  \n9609                           Who's the Caboose? (1997)  Comedy|Documentary  \n23971                                    Not Cool (2014)              Comedy  \n24005  Case of the Grinning Cat, The (Chats perchés) ...         Documentary  \n25525                   Pleasure at Her Majesty's (1976)  Comedy|Documentary  \n8605                                Cardinal, The (1963)               Drama  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_categories_df = pd.DataFrame(\n",
    "    {'movie_cat_code': range(N_movies),\n",
    "     'movieId': ratings['movieId'].astype('category').cat.categories}\n",
    ")\n",
    "\n",
    "fit_movie_means = q_movie_betas.mean().eval()\n",
    "movie_categories_df['fit_beta'] = fit_movie_means\n",
    "movie_betas_df = movie_categories_df.merge(movies, on = 'movieId', how='left')\n",
    "movie_betas_df.sort_values(['fit_beta']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "And just to check our Ids are matched up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   movieId  movie_cat_code  fit_beta                    title  \\\n0        1               0 -1.579556         Toy Story (1995)   \n1        2               1 -1.182469           Jumanji (1995)   \n2        3               2  0.065379  Grumpier Old Men (1995)   \n\n                                        genres  \n0  Adventure|Animation|Children|Comedy|Fantasy  \n1                   Adventure|Children|Fantasy  \n2                               Comedy|Romance  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_betas_df.sort_values('movie_cat_code')[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ratings['movie_cat_code'] = ratings['movieId'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   userId  movieId  rating   timestamp  \\\n0       1        2     3.5  1112486027   \n1       1       29     3.5  1112484676   \n2       1       32     3.5  1112484819   \n3       1       47     3.5  1112484727   \n4       1       50     3.5  1112484580   \n\n                                               title  \\\n0                                     Jumanji (1995)   \n1  City of Lost Children, The (Cité des enfants p...   \n2          Twelve Monkeys (a.k.a. 12 Monkeys) (1995)   \n3                        Seven (a.k.a. Se7en) (1995)   \n4                         Usual Suspects, The (1995)   \n\n                                   genres  movie_cat_code  \n0              Adventure|Children|Fantasy               1  \n1  Adventure|Drama|Fantasy|Mystery|Sci-Fi              28  \n2                 Mystery|Sci-Fi|Thriller              31  \n3                        Mystery|Thriller              46  \n4                  Crime|Mystery|Thriller              49  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Should check a bit more, but it looks good so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       movieId  movie_cat_code  fit_beta  \\\n15900    80742           15900  4.280601   \n20026    98989           20026  3.785681   \n18343    91784           18343  3.719136   \n19513    96923           19513  3.636514   \n21100   103210           21100  3.588994   \n\n                                                   title  \\\n15900       Last Letter, The (La dernière lettre) (2002)   \n20026                               Ghost Machine (2010)   \n18343                       Girl Walks Into a Bar (2011)   \n19513                       2-Headed Shark Attack (2012)   \n21100  Fullmetal Alchemist: The Sacred Star of Milos ...   \n\n                           genres  \n15900                       Drama  \n20026      Action|Sci-Fi|Thriller  \n18343        Comedy|Drama|Fantasy  \n19513               Comedy|Horror  \n21100  Action|Adventure|Animation  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_betas_df.sort_values(['fit_beta'], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "It pretty clearly looks to me like the model is not yet finding ratings that make any sense at all.  Let's see if it's putting anything into the latent dimensions.  We should be reliably recovering some well known highly rated movies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Let's also check the other learned parameters to see if they make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mu is at [-0.03395778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma for movies is at [ 1.72941291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma for users is at [ 1.26464629]\n"
     ]
    }
   ],
   "source": [
    "print('Mu is at {}'.format(q_mu.mean().eval()))\n",
    "\n",
    "print('Sigma for movies is at {}'.format(np.sqrt(np.exp(q_lnvar_users.mean().eval()))))\n",
    "print('Sigma for users is at {}'.format(np.sqrt(np.exp(q_lnvar_movies.mean().eval()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can also check out the distribution of fit offsets for movies. Nothing too concerning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16ab68190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, _, _ = plt.hist(fit_movie_means, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "OK, so it does not look like I am grabbing the best movies.  \n",
    "\n",
    "These are pretty much random, so I must be doing the IDs incorrectly.  I could also try displaying the most reviewed movies in two dimensions.  But let's first make sure I have the IDs right. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#  Visualizing the Latent Dimensions\n",
    "\n",
    "Now let's see if the factorization has learned meaningfull embeddings.\n",
    "\n",
    "First let's pick a small subset of the movies to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "movie_counts = ratings['movieId'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "name": "python2"
  },
  "name": "pcf_of_movielens_ratings.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
