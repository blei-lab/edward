\title{Tutorials}

\subsection{Tutorials}

Edward provides a testbed for rapid experimentation and research with
probabilistic models. Here we show how to apply this process for
diverse learning tasks.

\href{supervised-regression}{Bayesian linear regression} \\
A fundamental model for supervised learning.

\href{batch-training}{Batch training} \\
How to train a model using only minibatches of data at a time.

\href{tensorboard}{TensorBoard} \\
Visualize learning, explore the computational graph, and diagnose training problems.

\href{automated-transformations}{Automated transformations} \\
Using transformations to easily work over constrained continuous support.

\href{linear-mixed-effects-models}{Linear mixed effects models} \\
Linear modeling of fixed and random effects.

\href{supervised-classification}{Gaussian process classification} \\
Learning a distribution over functions for supervised classification.

\href{unsupervised}{Mixture models} \\
Unsupervised learning by clustering data points.

\href{latent-space-models}{Latent space models} \\
Analyzing connectivity patterns in neural data.

\href{mixture-density-network}{Mixture density networks} \\
A neural density estimator for solving inverse problems.

\href{gan}{Generative adversarial networks} \\
Building a deep generative model of MNIST digits.

\href{decoder}{Probabilistic decoder} \\
A model of latent codes in information theory.

\href{inference-networks}{Inference networks} \\
How to amortize computation for training and testing models.

\href{bayesian-neural-network}{Bayesian neural network} \\
Bayesian analysis with neural networks.

\href{probabilistic-pca}{Probabilistic PCA} \\
Dimensionality reduction with latent variables.

If you're interested in contributing a tutorial, checking out the
\href{/contributing}{contributing page}.

\subsubsection{Videos}

\begin{itemize}
  \item
  \href{https://www.youtube.com/watch?list=PLpTp0l_CVmgwyAthrUmmdIFiunV1VvicM&v=1zNNLHyeWok}
  {Probabilistic Programming with GPs}
  by Dustin Tran. Gaussian Process Summer School, 09/2017.
  \item
  \href{https://youtu.be/fR5Wvb86-IU}
  {Intro to Bayesian Machine Learning with PyMC3 and Edward}
  by Torsten Scholak, Diego Maniloff. PyCon, 05/2017.
  \item
  \href{https://www.youtube.com/watch?v=I09QVNrUS3Q}
  {Bayesian Deep Learning with Edward (and a trick using Dropout)}
  by Andrew Rowan. PyData London, 05/2017.
  \item
  \href{http://bit.ly/2k9QM3J}
  {Edward: A library for probabilistic modeling, inference, and
  criticism}
  by Dustin Tran. NYU ML Meetup, 01/2017.
  \item
  \href{https://www.pscp.tv/hugo_larochelle/1yNGanvpOPjJj}
  {Edward: A library for probabilistic modeling, inference, and criticism}
  by Dustin Tran. Twitter, 09/2016.
\end{itemize}

We also have a
\href{https://github.com/edwardlib/papers}{community repository}
for sharing content such as papers, posters, and slides.

\subsubsection{Background}

For more background and notation, see the pages below.
\begin{itemize}
  \item \href{model}{Probabilistic models}
  \item \href{inference}{Inference of probabilistic models}
  \begin{itemize}
   \item \href{variational-inference}{Variational inference}
   \item \href{klqp}{$\text{KL}(q\|p)$ minimization}
   \item \href{klpq}{$\text{KL}(p\|q)$ minimization}
   \item \href{map}{Maximum a posteriori estimation}
   \item \href{map-laplace}{Laplace approximation}
  \end{itemize}
  \item \href{criticism}{Model criticism}
\end{itemize}

There are also companion webpages for several papers about Edward.
\begin{itemize}
\item
\href{/iclr2017}{"Deep probabilistic programming" at ICLR 2017}
\end{itemize}
