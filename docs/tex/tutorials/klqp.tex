\title{KL(q||p) minimization}

\subsection{$\text{KL}(q\|p)$ minimization}

One form of variational inference minimizes the Kullback-Leibler
divergence \textbf{from} $q(\mathbf{z}\;;\;\lambda)$ \textbf{to}
$p(\mathbf{z} \mid \mathbf{x})$,
\begin{align*}
  \lambda^*
  &=
  \arg\min_\lambda \text{KL}(
  q(\mathbf{z}\;;\;\lambda)
  \;\|\;
  p(\mathbf{z} \mid \mathbf{x})
  )\\
  &=
  \arg\min_\lambda\;
  \mathbb{E}_{q(\mathbf{z}\;;\;\lambda)}
  \big[
  \log q(\mathbf{z}\;;\;\lambda)
  -
  \log p(\mathbf{z} \mid \mathbf{x})
  \big].
\end{align*}
The KL divergence is a non-symmetric, information theoretic measure of
similarity between two probability distributions
\citep{hinton1993keeping,waterhouse1996bayesian,jordan1999introduction}.

\subsubsection{The Evidence Lower Bound}

The above optimization problem is intractable because it directly
depends on the posterior $p(\mathbf{z} \mid \mathbf{x})$. To tackle
this, consider the property
\begin{align*}
  \log p(\mathbf{x})
  &=
  \text{KL}(
  q(\mathbf{z}\;;\;\lambda)
  \;\|\;
  p(\mathbf{z} \mid \mathbf{x})
  )\\
  &\quad+\;
  \mathbb{E}_{q(\mathbf{z}\;;\;\lambda)}
  \big[
  \log p(\mathbf{x}, \mathbf{z})
  -
  \log q(\mathbf{z}\;;\;\lambda)
  \big]
\end{align*}
where the left hand side is the logarithm of the marginal likelihood
$p(\mathbf{x}) = \int p(\mathbf{x}, \mathbf{z}) \text{d}\mathbf{z}$,
also known as the model evidence. (Try deriving this using Bayes'
rule!)

The evidence is a constant with respect to the variational parameters
$\lambda$, so we can minimize $\text{KL}(q\|p)$ by instead maximizing
the Evidence Lower BOund,
\begin{align*}
  \text{ELBO}(\lambda)
  &=\;
  \mathbb{E}_{q(\mathbf{z}\;;\;\lambda)}
  \big[
  \log p(\mathbf{x}, \mathbf{z})
  -
  \log q(\mathbf{z}\;;\;\lambda)
  \big].
\end{align*}
In the ELBO, both $p(\mathbf{x}, \mathbf{z})$ and
$q(\mathbf{z}\;;\;\lambda)$ are tractable. The optimization problem we
seek to solve becomes
\begin{align*}
  \lambda^*
  &=
  \arg \max_\lambda \text{ELBO}(\lambda).
\end{align*}
As per its name, the ELBO is a lower bound on the evidence, and
optimizing it tries to maximize the probability of observing the data.
What does maximizing the ELBO do? Splitting the ELBO reveals a trade-off
\begin{align*}
  \text{ELBO}(\lambda)
  &=\;
  \mathbb{E}_{q(\mathbf{z} \;;\; \lambda)}[\log p(\mathbf{x}, \mathbf{z})]
  - \mathbb{E}_{q(\mathbf{z} \;;\; \lambda)}[\log q(\mathbf{z}\;;\;\lambda)],
\end{align*}
where the first term represents an energy and the second term
(including the minus sign) represents the entropy of $q$.
The energy encourages $q$ to focus probability mass where the
model puts high probability, $p(\mathbf{x}, \mathbf{z})$.
The entropy encourages $q$ to spread probability mass to avoid
concentrating to one location.

Edward uses two generic strategies to obtain gradients for
optimization.
\begin{itemize}
    \item \href{/tutorials/klqp-score}{Score function gradient}
    \item \href{/tutorials/klqp-reparam}{Reparameterization gradient}
  \end{itemize}

\subsubsection{References}\label{references}

